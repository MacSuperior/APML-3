{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3 â€“ Topic Modeling and Clustering for Online Social Media Data\n",
    "\n",
    "*Due: Friday January 12 at 14:00 CET*\n",
    "\n",
    "In the third assignment of the course Applications of Machine Learning (INFOB3APML), you will learn to use topic modeling and clustering to identify topics in online social media data. The objectives of this assignment are:\n",
    "- understand and process the text data\n",
    "- use the clustering algorithm to determine clusters in real-life data\n",
    "- use the Latent Dirichlet Allocation algorithm to identify discussed topics in real-life text data \n",
    "- use the visualization tools to validate the results of unsupervised learning and interpret your findings\n",
    "- reflect on the difference between two type of unsupervised learning algorithms\n",
    "\n",
    "In this assignment, you are going to discover the different â€˜topicsâ€™ from a real social media text dataset. The project is divided into two parts (4 subtasks):\n",
    "\n",
    "- The first part contains data processing (1.1) and feature extraction (1.2) from the raw text data.\n",
    "- In the second part, you will implement two methods (2.1), a topic modeling method and a clustering method, to identify topics from the processed data. Then, the evaluation will be done by using visualization tools (2.2). \n",
    "\n",
    "Provided files:\n",
    "- The dataset: data/raw_data.txt\n",
    "- A tutorial notebook showcases some packages you could use for this assignment (optional): Ass3_tutorial.ipynb\n",
    "- Some sample visualization codes for interpreting the topic results: viz_example.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import spacy\n",
    "import re\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# TODO: import the packages\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Dataset:\n",
    " The data used in this assignment is Dutch text data. We collected the COVID-19 crisis related messages from online social media (Twitter) from January to November 2021. Then, a subset of raw tweets was randomly sampled. In total, our dataset includes the text data of about 100K messages. **To protect the data privacy, please only use this dataset within the course.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# read the data\n",
    "\n",
    "def phase0_open_txt_stream(filename):\n",
    "    return io.open(filename, \"r\", encoding=\"utf-8\")\n",
    "\n",
    "\n",
    "pipe = phase0_open_txt_stream(\"others/others/data/raw_data.txt\")\n",
    "\n",
    "all_messages = []\n",
    "\n",
    "for message in pipe:\n",
    "    all_messages.append(message.strip())\n",
    "\n",
    "pipe.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100701 messages\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(all_messages)} messages\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 0. Before you start the Project: \n",
    " The provided messages in the raw dataset were collected based on 10 different themes that relate to the COVID-19 crisis. Here is a list of all themes:\n",
    " -\tLockdown\n",
    " -\tFace mask\n",
    " -\tSocial distancing\n",
    " -\tLoneliness\n",
    " -\tHappiness\n",
    " -\tVaccine\n",
    " -\tTesting\n",
    " -  Curfew\n",
    " -  Covid entry pass\n",
    " -  Work from home\n",
    "\n",
    "Before starting your project, you need to first filter the messages (all messages are in Dutch) and use the messages belonging to only one theme for the topic identification. \n",
    " \n",
    "If you have submitted the theme preference, you can skip the following paragraph.\n",
    "\n",
    "*Please notice that there will be maximum two teams working on a same theme. In this way, we hope that each group will develop their own dataset and come up with interesting results.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 1.1 Data Processing\n",
    " In the first part of the assignment, please first filter the messages and use the messages belonging to your allocated theme for the identification of topics. For that you will need to:\n",
    " -\tDesign your query (e.g. a regular expression or a set of keywords) and filter the related messages for your allocated theme. \n",
    " -\tClean your filtered messages and preprocess them into the right representation. Please refer to the text data pre-processing and representation methods discussed in the lecture. You may use some of the recommended packages for text data preprocessing and representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: filter the related messages\n",
    "facemask_messages = []\n",
    "\n",
    "facemask_pattern = r\"mondkap|(mond)?masker|bekluier|beklap|\\bmask\\b|muilkorf|facemask|face mask|monddoek|face shield\"\n",
    "for message in all_messages:\n",
    "    if re.search(facemask_pattern, message.lower()):\n",
    "        facemask_messages.append(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9416 messages about facemasks\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(facemask_messages)} messages about facemasks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['@WilmadeJong1 @mariannezw @HellieS8 Precies. Mondkapje, binnen blijven,  en angst verzwakken je immuunsysteem. Langdurig gebruik van een mondkapje kan zelfs schimmels veroorzaken die diep in de longen gaan zitten. Gevolg longontsteking. Bij ouderen zeer gevaarlijk!\\n',\n",
       " '@Sandoka04120321 @BiancaLesman @telegraaf Dit moet stoppen!\\\\n\\\\n#GERRITSENðŸ—½ #PvdKB #TK2021ðŸ‡³ðŸ‡± SAMEN STERK ðŸ‘Š\\\\n\\\\n#jeugdzorg #jeugdbescherming #school #onderwijs #rechtstaat\\\\n#ouders #kinderen #onrecht \\\\n#kindermishandeling #kindermisbruik #revolutie \\\\n#corona #covid #lockdown #mondkapjes #verkiezingen @PvdKB_ #neurenberg #rechten https://t.co/VfjAOP7tb9\\n',\n",
       " '@RolandPierik @hugodejonge En daar is dus al die discussie over. Mondkapjes wel/niet, wie wel, wie niet, medisch/niet-medisch. Afstand houden, aerosolen, ventileren. Kerk en Ikea vs het sportveld. Scholen open, scholen dicht, etc, etc. Die regels zijn juist niet allemaal even voorstelbaar cq logisch.\\n',\n",
       " '@waneijs 2het is een raar virus maar de mensen die er mee jn contact komen zijn niet besmet en dat is heel raar. En daarom weegt het niet op tegen het maatschappelijke en economische  leed wat er aangericht wordt. Mondkapjes en lock down werkt ook niet opengooien die boel\\n',\n",
       " 'Bv: het afdwingen van invorderen van mondkapjes bij minister Bruins vlak voordat hij omviel. Leidde tot minder handel en tegenzin om aan Nederland te leveren. Invorderen moet je alleen doen als een product al hier is en de ander het weigert te leveren. Nog beter is: zelf maken.\\n']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "facemask_messages[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: clean and preprocess the messages\n",
    "\n",
    "# V lowercasing\n",
    "# V remove punctuation / special chars\n",
    "# V stopword removal\n",
    "# V remove of urls\n",
    "# V tokenization\n",
    "# V stemming / lemmatization\n",
    "# X text normalization / representation\n",
    "\n",
    "def lowercase_doc(doc: str) -> str:\n",
    "    \"\"\"\n",
    "    Transform a document into lowercase.\n",
    "    \"\"\"\n",
    "    return doc.lower()\n",
    "\n",
    "\n",
    "def remove_urls(doc: str) -> str:\n",
    "    \"\"\"\n",
    "    Return a document stripped of any URLs.\n",
    "    \"\"\"\n",
    "    url_pattern = r\"http[s]*\\S+\"\n",
    "    clean_doc = re.sub(url_pattern, ' ', doc)\n",
    "    return clean_doc\n",
    "\n",
    "\n",
    "def remove_punctuation(doc: str) -> str: \n",
    "    \"\"\"\n",
    "    Transform a text document into a document without punctuation, digits, newline characters and twitter tags (@HugodeJonge, etc.).\n",
    "    \"\"\"\n",
    "    doc = doc.replace('\\\\n', ' ')\n",
    "\n",
    "    punct_pattern = r\"@\\w+\\b|[^\\w\\s]|\\d+\"\n",
    "    \n",
    "    clean_doc = re.sub(punct_pattern, ' ', doc, )\n",
    "\n",
    "    return clean_doc\n",
    "    \n",
    "\n",
    "def tokenize(doc: str, nlp, lemma = True) -> list:\n",
    "    \"\"\"\n",
    "    Transform string document into a tokenized list.\n",
    "    The lemma parameter specifiec whether to return lemmatized words or not.\n",
    "    \"\"\"\n",
    "    if lemma:\n",
    "        return [token.lemma_ for token in nlp(doc) if not token.is_stop]\n",
    "    else:\n",
    "        return [token for token in nlp(doc) if not token.is_stop]\n",
    "\n",
    "\n",
    "def delete_only_consonant_words(doc: list) -> list:\n",
    "    \"\"\"\n",
    "    Delete all words from a list containing only consonants (such as 'vs' or typos such as 'js' instead of 'is')\n",
    "    \"\"\"\n",
    "    vowels = ['a', 'e', 'i', 'o', 'u', 'y']\n",
    "    return [word for word in doc if any(vowel in word for vowel in vowels)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"nl_core_news_sm\")\n",
    "\n",
    "cleaned_messages = []\n",
    "\n",
    "for sentence in facemask_messages:\n",
    "\n",
    "    sentence = lowercase_doc(sentence)\n",
    "    sentence = remove_urls(sentence)\n",
    "    sentence = remove_punctuation(sentence)\n",
    "    tokenized = tokenize(sentence, nlp)\n",
    "    cleaned = delete_only_consonant_words(tokenized)\n",
    "\n",
    "    cleaned_message = ' '.join(cleaned)\n",
    "    cleaned_messages.append(cleaned_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before cleaning:\n",
      "@WilmadeJong1 @mariannezw @HellieS8 Precies. Mondkapje, binnen blijven,  en angst verzwakken je immuunsysteem. Langdurig gebruik van een mondkapje kan zelfs schimmels veroorzaken die diep in de longen gaan zitten. Gevolg longontsteking. Bij ouderen zeer gevaarlijk!\n",
      "After cleaning:\n",
      "mondkap blijven angst verzwakken immuunsysteem langdurig gebruik mondkap schimmel veroorzaken diep long gaan zitten gevolg longontsteking oud gevaarlijk\n",
      "\n",
      "Before cleaning:\n",
      "@Sandoka04120321 @BiancaLesman @telegraaf Dit moet stoppen!\\n\\n#GERRITSENðŸ—½ #PvdKB #TK2021ðŸ‡³ðŸ‡± SAMEN STERK ðŸ‘Š\\n\\n#jeugdzorg #jeugdbescherming #school #onderwijs #rechtstaat\\n#ouders #kinderen #onrecht \\n#kindermishandeling #kindermisbruik #revolutie \\n#corona #covid #lockdown #mondkapjes #verkiezingen @PvdKB_ #neurenberg #rechten https://t.co/VfjAOP7tb9\n",
      "After cleaning:\n",
      "stoppen gerritsen samen sterk jeugdzorg jeugdbescherming school onderwijs rechtstaat ouder kind onrecht kindermishandeling kindermisbruik revolutie corona covid lockdown mondkap verkiezing Neurenberg recht\n",
      "\n",
      "Before cleaning:\n",
      "@RolandPierik @hugodejonge En daar is dus al die discussie over. Mondkapjes wel/niet, wie wel, wie niet, medisch/niet-medisch. Afstand houden, aerosolen, ventileren. Kerk en Ikea vs het sportveld. Scholen open, scholen dicht, etc, etc. Die regels zijn juist niet allemaal even voorstelbaar cq logisch.\n",
      "After cleaning:\n",
      "discussie mondkap medisch medisch afstand houden aerosol ventileur kerk Ikea sportveld school open school dicht regel allemaal voorstelbaar logisch\n",
      "\n",
      "Before cleaning:\n",
      "@waneijs 2het is een raar virus maar de mensen die er mee jn contact komen zijn niet besmet en dat is heel raar. En daarom weegt het niet op tegen het maatschappelijke en economische  leed wat er aangericht wordt. Mondkapjes en lock down werkt ook niet opengooien die boel\n",
      "After cleaning:\n",
      "raar virus mens mee contact komen besmet heel raar weegmen maatschappelijk economisch lijden aanrichten mondkap lock down werken opengooien boel\n",
      "\n",
      "Before cleaning:\n",
      "Bv: het afdwingen van invorderen van mondkapjes bij minister Bruins vlak voordat hij omviel. Leidde tot minder handel en tegenzin om aan Nederland te leveren. Invorderen moet je alleen doen als een product al hier is en de ander het weigert te leveren. Nog beter is: zelf maken.\n",
      "After cleaning:\n",
      "bijvoorbeeld afdwingen invorderen mondkap minister bruin vlak omviel leiden handel tegenzin Nederland leveren invorderen product weigeren leveren maken\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for before, after in zip(facemask_messages[0:5], cleaned_messages[0:5]):\n",
    "    print(f\"Before cleaning:\\n{before}After cleaning:\\n{after}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: represent the messages into formats that can be used in clustering or LDA algorithms (you may need different represention for two algorithms)\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "x = vectorizer.fit_transform(cleaned_messages)\n",
    "print(x.toarray())\n",
    "print(vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 1.2 Exploratory Data Analysis\n",
    " After preprocessing the data, create at least 2 figures or tables that help you understand the data.\n",
    "\n",
    " While exploring the data, you may also think about questions such as:\n",
    " - Can you spot any differences between Twitter data and usual text data?\n",
    " - Does your exploration reveal some issues that would make it difficult to interpret the topics?\n",
    " - Can you improve the data by adding additional preprocessing steps?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: plot figure(s)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Topic modelling and clustering\n",
    " In the second part of the assignment, you will first:\n",
    " -\tImplement a Latent Dirichlet Allocation (LDA) algorithm to identify the discussed topics for your theme\n",
    " -\tImplement a clustering method  to cluster messages into different groups, then represent the topic of each cluster using a bag of words\n",
    "\n",
    "While implementing the algorithms, you may use the codes from the recommended packages. In the final report, please explain reasons to select the used algorithm/package. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: topic modeling using the LDA algorithm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: cluster the messages using a clustering algorithm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 2.2 Results, evaluation and Interpretation \n",
    " \n",
    "Finally, you will describe, evaluate and interpret your findings from two methods. \n",
    "\n",
    "- In the report, you need to describe and discuss the similarity and difference of results from two methods.\n",
    "- While evaluating the results, human judgment is very important, so visualization techniques are helpful to evaluate the identified topics in an interpreted manner. \n",
    "    \n",
    "1. For evaluating the topic modelling algorithm, please first use the interactive tool **[pyLDAvis](https://nbviewer.jupyter.org/github/bmabey/pyLDAvis/blob/master/notebooks/pyLDAvis_overview.ipynb#topic=0&lambda=1&term=)** to examine the inter-topic separation of your findings. \n",
    "\n",
    "2. For interpreting the identified topics / clusters of both algorithms, we provide example code for several visualization techiques. You can use multiple ones to evaluate your results or come up with visualisations on your own. The files contain examples for how to use the visualisation functions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: evaluation \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus Tasks \n",
    "\n",
    "We would like to challenge you with the following bonus task. For each task that is successfully completed, you may obtain max. 1 extra point. \n",
    "\n",
    "1. Implement another clustering algorithm or design your own clustering algorithm. Discuss your findings and explain why this is a better (or worse) clustering algorithm than the above one (the clustering algorithm, not LDA).\n",
    "\n",
    "2. Can you think of other evaluation methods than the provided visualization techniques? If so, implement one and explain why it is a good evaluation for our task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
